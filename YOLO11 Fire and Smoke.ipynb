{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "G4QMfeJ4yJDl",
      "metadata": {
        "id": "G4QMfeJ4yJDl"
      },
      "source": [
        "# YOLO11 Training and Ablation Notebook (Clean Import)\n",
        "Upload your yolo11.yaml -> generate n/s/m/l/x configs -> run training -> run ablation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4900351",
      "metadata": {},
      "source": [
        "### Prepare YOLO11 files for Upload and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MCL07P-iyJDn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "MCL07P-iyJDn",
        "outputId": "613e0ef7-c024-4252-a73c-d81a1e65e68b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import os\n",
        "\n",
        "def upload_yaml_file():\n",
        "    \"\"\"Open file dialog and return selected YAML file path\"\"\"\n",
        "    print(\"Upload your yolo11.yaml file...\")\n",
        "    \n",
        "    # Create hidden tkinter root window\n",
        "    root = tk.Tk()\n",
        "    root.withdraw()\n",
        "    root.attributes('-topmost', True)  # Bring dialog to front\n",
        "    \n",
        "    # Open file dialog\n",
        "    BASE_YAML = filedialog.askopenfilename(\n",
        "        title=\"Upload your yolo11.yaml file\",\n",
        "        filetypes=[\n",
        "            (\"YAML files\", \"*.yaml *.yml\"),\n",
        "            (\"All files\", \"*.*\")\n",
        "        ],\n",
        "        initialdir=os.getcwd()\n",
        "    )\n",
        "    \n",
        "    root.destroy()\n",
        "    \n",
        "    # Display result\n",
        "    if BASE_YAML and os.path.exists(BASE_YAML):\n",
        "        filename = os.path.basename(BASE_YAML)\n",
        "        print(f\"Uploaded: {filename}\")\n",
        "        return BASE_YAML\n",
        "    else:\n",
        "        print(\"No file chosen\")\n",
        "        return None\n",
        "\n",
        "# Usage\n",
        "BASE_YAML = upload_yaml_file()\n",
        "\n",
        "if BASE_YAML:\n",
        "    print(f\"File path: {BASE_YAML}\")\n",
        "else:\n",
        "    print(\"Upload cancelled or file not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pH8OdcbnyJDn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH8OdcbnyJDn",
        "outputId": "c4fa8f47-9a4f-49a5-e64b-c7a1177f00b4"
      },
      "outputs": [],
      "source": [
        "import yaml, copy\n",
        "import os\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "\n",
        "scale_settings = {\n",
        "    \"n\":[0.50,0.25,1024],\n",
        "    \"s\":[0.50,0.50,1024],\n",
        "    \"m\":[0.50,1.00,512],\n",
        "    \"l\":[1.00,1.00,512],\n",
        "    \"x\":[1.00,1.50,512],\n",
        "}\n",
        "\n",
        "with open(BASE_YAML,\"r\") as f:\n",
        "    base_cfg=yaml.safe_load(f)\n",
        "\n",
        "if \"scales\" in base_cfg:\n",
        "    del base_cfg[\"scales\"]\n",
        "\n",
        "# Let user select output directory\n",
        "root = tk.Tk()\n",
        "root.withdraw()\n",
        "root.attributes('-topmost', True)\n",
        "\n",
        "print(\"Select output directory for generated YAML files...\")\n",
        "output_dir = filedialog.askdirectory(\n",
        "    title=\"Select Output Directory\",\n",
        "    initialdir=os.path.dirname(BASE_YAML) or os.getcwd()\n",
        ")\n",
        "root.destroy()\n",
        "\n",
        "if not output_dir:\n",
        "    print(\"No directory selected. Using current directory.\")\n",
        "    output_dir = os.getcwd()\n",
        "\n",
        "generated=[]\n",
        "for name,(d,w,mxc) in scale_settings.items():\n",
        "    cfg=copy.deepcopy(base_cfg)\n",
        "    cfg[\"depth_multiple\"]=d\n",
        "    cfg[\"width_multiple\"]=w\n",
        "    cfg[\"max_channels\"]=mxc\n",
        "    out = os.path.join(output_dir, f\"yolo11{name}.yaml\")\n",
        "    with open(out,\"w\") as f: yaml.dump(cfg,f)\n",
        "    generated.append(out)\n",
        "    print(\"Generated:\", out)\n",
        "\n",
        "generated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2614a70d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install roboflow\n",
        "#%pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oZKvmp9m7ni2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZKvmp9m7ni2",
        "outputId": "2629df2e-49dc-4ced-9386-628464eed225"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os, torch, pandas as pd\n",
        "from IPython.display import Image, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3843678",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog, Checkbutton, IntVar, Button, Label\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import shutil\n",
        "\n",
        "# ============ STEP 1: SELECT DATA.YAML ============\n",
        "\n",
        "root = tk.Tk()\n",
        "root.withdraw()\n",
        "root.attributes('-topmost', True)\n",
        "\n",
        "print(\"Step 1: Select your data.yaml file...\")\n",
        "DATA_YAML_PATH = filedialog.askopenfilename(\n",
        "    title=\"Select data.yaml file\",\n",
        "    filetypes=[(\"YAML files\", \"*.yaml *.yml\"), (\"All files\", \"*.*\")]\n",
        ")\n",
        "\n",
        "if not DATA_YAML_PATH:\n",
        "    raise ValueError(\"No data.yaml file selected!\")\n",
        "\n",
        "print(f\"‚úì Selected: {DATA_YAML_PATH}\")\n",
        "\n",
        "# ============ STEP 2: SELECT VARIANT YAML FILES ============\n",
        "\n",
        "print(\"\\nStep 2: Select which model variants to use...\")\n",
        "\n",
        "def select_variant_files():\n",
        "    \"\"\"Let user select which variant YAML files to use with checkboxes, then select files\"\"\"\n",
        "    \n",
        "    selection_window = tk.Toplevel()\n",
        "    selection_window.title(\"Select YOLO11 Variants\")\n",
        "    selection_window.geometry(\"350x280\")\n",
        "    selection_window.attributes('-topmost', True)\n",
        "    \n",
        "    Label(selection_window, text=\"Select variants to train:\", \n",
        "          font=(\"Arial\", 12, \"bold\")).pack(pady=10)\n",
        "    \n",
        "    Label(selection_window, text=\"(You'll select file locations next)\", \n",
        "          font=(\"Arial\", 9, \"italic\"), fg=\"gray\").pack()\n",
        "    \n",
        "    variants_dict = {}\n",
        "    available_variants = [\"n\", \"s\", \"m\", \"l\", \"x\"]\n",
        "    \n",
        "    for variant in available_variants:\n",
        "        var = IntVar()\n",
        "        Checkbutton(\n",
        "            selection_window, \n",
        "            text=f\"YOLO11{variant} - {variant.upper()} variant\", \n",
        "            variable=var,\n",
        "            font=(\"Arial\", 10)\n",
        "        ).pack(anchor='w', padx=30, pady=5)\n",
        "        variants_dict[variant] = var\n",
        "    \n",
        "    selected = []\n",
        "    \n",
        "    def on_submit():\n",
        "        nonlocal selected\n",
        "        selected = [k for k, v in variants_dict.items() if v.get() == 1]\n",
        "        selection_window.destroy()\n",
        "    \n",
        "    Button(\n",
        "        selection_window, \n",
        "        text=\"Next: Select Files\", \n",
        "        command=on_submit, \n",
        "        bg=\"green\", \n",
        "        fg=\"white\", \n",
        "        font=(\"Arial\", 10, \"bold\"),\n",
        "        padx=20,\n",
        "        pady=5\n",
        "    ).pack(pady=15)\n",
        "    \n",
        "    selection_window.wait_window()\n",
        "    return selected\n",
        "\n",
        "# Get which variants user wants\n",
        "selected_variant_names = select_variant_files()\n",
        "\n",
        "if not selected_variant_names:\n",
        "    root.destroy()\n",
        "    raise ValueError(\"No variants selected!\")\n",
        "\n",
        "print(f\"‚úì Selected variants: {selected_variant_names}\")\n",
        "\n",
        "# ============ STEP 3: SELECT FILE LOCATIONS FOR EACH VARIANT ============\n",
        "\n",
        "print(\"\\nStep 3: Select the YAML file location for each variant...\")\n",
        "\n",
        "variants = []\n",
        "variant_file_map = {}\n",
        "\n",
        "for variant_name in selected_variant_names:\n",
        "    print(f\"\\nSelect YOLO11{variant_name}.yaml file location...\")\n",
        "    \n",
        "    # Suggest default filename\n",
        "    suggested_name = f\"yolo11{variant_name}.yaml\"\n",
        "    \n",
        "    file_path = filedialog.askopenfilename(\n",
        "        title=f\"Select yolo11{variant_name}.yaml file\",\n",
        "        filetypes=[(\"YAML files\", \"*.yaml *.yml\"), (\"All files\", \"*.*\")],\n",
        "        initialfile=suggested_name\n",
        "    )\n",
        "    \n",
        "    if not file_path:\n",
        "        print(f\"‚ö†Ô∏è Warning: Skipping {variant_name} variant (no file selected)\")\n",
        "        continue\n",
        "    \n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ö†Ô∏è Warning: File not found: {file_path}\")\n",
        "        continue\n",
        "    \n",
        "    variants.append(file_path)\n",
        "    variant_file_map[variant_name] = file_path\n",
        "    print(f\"‚úì {variant_name}: {file_path}\")\n",
        "\n",
        "root.destroy()\n",
        "\n",
        "if not variants:\n",
        "    raise ValueError(\"No valid variant files selected!\")\n",
        "\n",
        "print(f\"\\n‚úÖ Total variants to train: {len(variants)}\")\n",
        "\n",
        "# ============ TRAINING LOOP ============\n",
        "\n",
        "ablation_metrics = {}\n",
        "all_losses = None\n",
        "model_performances = {}\n",
        "\n",
        "for v in variants:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üöÄ Training model: {v}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    model = YOLO(v)\n",
        "    \n",
        "    # Train model\n",
        "    results = model.train(\n",
        "        data=DATA_YAML_PATH,\n",
        "        epochs=100,\n",
        "        imgsz=640,\n",
        "        batch=8,\n",
        "        name=f\"ablation_{os.path.basename(v).replace('.yaml','')}\",\n",
        "        project=\"runs/ablation\",\n",
        "        device=0 if torch.cuda.is_available() else \"cpu\",\n",
        "        plots=True\n",
        "        # exist_ok=True  # This will overwrite instead of creating new folders\n",
        "    )\n",
        "    \n",
        "    # Validate model\n",
        "    res = model.val()\n",
        "    ablation_metrics[v] = res\n",
        "    \n",
        "    # Store performance metric (mAP50-95)\n",
        "    model_performances[v] = {\n",
        "        'map50_95': res.box.map,\n",
        "        'map50': res.box.map50,\n",
        "        'map75': res.box.map75,\n",
        "        'model_path': f\"runs/ablation/ablation_{os.path.basename(v).replace('.yaml','')}/weights/best.pt\"\n",
        "    }\n",
        "    \n",
        "    # Display confusion matrix\n",
        "    cm = f\"{res.save_dir}/confusion_matrix.png\"\n",
        "    if os.path.exists(cm):\n",
        "        print(f\"\\nüìä Confusion Matrix for {v}\")\n",
        "        display(Image(cm))\n",
        "    \n",
        "    # Collect training results\n",
        "    csv_path = f\"runs/ablation/ablation_{os.path.basename(v).replace('.yaml','')}/results.csv\"\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        df[\"scale\"] = os.path.basename(v).replace(\".yaml\",\"\")\n",
        "        all_losses = df if all_losses is None else pd.concat([all_losses, df], ignore_index=True)\n",
        "\n",
        "# ============ SAVE BEST & WORST MODELS ============\n",
        "\n",
        "# Rank models by mAP50-95\n",
        "sorted_models = sorted(model_performances.items(), key=lambda x: x[1]['map50_95'], reverse=True)\n",
        "best_model = sorted_models[0]\n",
        "worst_model = sorted_models[-1]\n",
        "\n",
        "# Create output directory (use same directory as data.yaml)\n",
        "output_dir = os.path.join(os.path.dirname(DATA_YAML_PATH), \"best_worst_models\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Copy best model\n",
        "best_src = best_model[1]['model_path']\n",
        "best_dst = os.path.join(output_dir, f\"BEST_model_{os.path.basename(best_model[0]).replace('.yaml','')}.pt\")\n",
        "shutil.copy2(best_src, best_dst)\n",
        "\n",
        "# Copy worst model\n",
        "worst_src = worst_model[1]['model_path']\n",
        "worst_dst = os.path.join(output_dir, f\"WORST_model_{os.path.basename(worst_model[0]).replace('.yaml','')}.pt\")\n",
        "shutil.copy2(worst_src, worst_dst)\n",
        "\n",
        "# ============ RESULTS SUMMARY ============\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ ABLATION STUDY COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìä MODEL PERFORMANCE RANKING:\")\n",
        "for i, (model_path, metrics) in enumerate(sorted_models, 1):\n",
        "    model_name = os.path.basename(model_path).replace('.yaml', '')\n",
        "    print(f\"{i}. {model_name:10s} | mAP50-95: {metrics['map50_95']:.4f} | mAP50: {metrics['map50']:.4f}\")\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL:\")\n",
        "print(f\"   Model: {os.path.basename(best_model[0]).replace('.yaml','')}\")\n",
        "print(f\"   mAP50-95: {best_model[1]['map50_95']:.4f}\")\n",
        "print(f\"   Saved to: {best_dst}\")\n",
        "\n",
        "print(f\"\\nüîª WORST MODEL:\")\n",
        "print(f\"   Model: {os.path.basename(worst_model[0]).replace('.yaml','')}\")\n",
        "print(f\"   mAP50-95: {worst_model[1]['map50_95']:.4f}\")\n",
        "print(f\"   Saved to: {worst_dst}\")\n",
        "\n",
        "print(f\"\\nüíæ All models saved in: runs/ablation/\")\n",
        "print(f\"üíæ Best/Worst models saved in: {output_dir}\")\n",
        "\n",
        "# Save performance comparison\n",
        "performance_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': os.path.basename(k).replace('.yaml',''),\n",
        "        'mAP50-95': v['map50_95'],\n",
        "        'mAP50': v['map50'],\n",
        "        'mAP75': v['map75'],\n",
        "        'File_Path': k\n",
        "    } for k, v in model_performances.items()\n",
        "]).sort_values('mAP50-95', ascending=False)\n",
        "\n",
        "perf_csv = os.path.join(output_dir, \"performance_comparison.csv\")\n",
        "performance_df.to_csv(perf_csv, index=False)\n",
        "print(f\"üìä Performance comparison saved: {perf_csv}\")\n",
        "\n",
        "# Display file mapping\n",
        "print(f\"\\nüìÅ VARIANT FILE MAPPING:\")\n",
        "for variant_name, file_path in variant_file_map.items():\n",
        "    print(f\"   {variant_name}: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bc1f3d",
      "metadata": {},
      "source": [
        "### Export Generated Outputs and Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f9c7c18",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (15, 10)\n",
        "\n",
        "# ============ CREATE RESULTS DIRECTORY ============\n",
        "\n",
        "# Create main results directory alongside data.yaml\n",
        "results_dir = os.path.join(os.path.dirname(DATA_YAML_PATH), \"results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Create subdirectories\n",
        "plots_dir = os.path.join(results_dir, \"plots\")\n",
        "metrics_dir = os.path.join(results_dir, \"metrics_csv\")\n",
        "models_dir = os.path.join(results_dir, \"best_worst_models\")\n",
        "\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìÅ RESULTS DIRECTORY STRUCTURE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Main results folder: {results_dir}\")\n",
        "print(f\"  ‚îú‚îÄ‚îÄ plots/              (all visualizations)\")\n",
        "print(f\"  ‚îú‚îÄ‚îÄ metrics_csv/        (all CSV files)\")\n",
        "print(f\"  ‚îî‚îÄ‚îÄ best_worst_models/  (best & worst .pt files)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"Generating comprehensive evaluation metrics and visualizations...\")\n",
        "\n",
        "# ============ SAVE INDIVIDUAL VARIANT METRICS ============\n",
        "\n",
        "print(\"\\nüìä Saving individual variant metrics to CSV...\")\n",
        "for v in variants:\n",
        "    scale_name = os.path.basename(v).replace('.yaml', '')\n",
        "    \n",
        "    # Copy individual results.csv\n",
        "    src_csv = f\"runs/ablation/ablation_{scale_name}/results.csv\"\n",
        "    if os.path.exists(src_csv):\n",
        "        dst_csv = os.path.join(metrics_dir, f\"training_metrics_{scale_name}.csv\")\n",
        "        shutil.copy2(src_csv, dst_csv)\n",
        "        print(f\"‚úì Saved: training_metrics_{scale_name}.csv\")\n",
        "\n",
        "# ============ SAVE COMBINED METRICS ============\n",
        "\n",
        "print(\"\\nüìä Saving combined training metrics...\")\n",
        "\n",
        "# Save all losses combined (all variants together)\n",
        "if all_losses is not None:\n",
        "    combined_csv = os.path.join(metrics_dir, \"all_variants_training_metrics.csv\")\n",
        "    all_losses.to_csv(combined_csv, index=False)\n",
        "    print(f\"‚úì Saved: all_variants_training_metrics.csv ({len(all_losses)} rows)\")\n",
        "\n",
        "# ============ SAVE PERFORMANCE SUMMARY ============\n",
        "\n",
        "print(\"\\nüìä Saving performance comparison...\")\n",
        "\n",
        "# Overall performance comparison\n",
        "perf_csv = os.path.join(metrics_dir, \"performance_comparison.csv\")\n",
        "performance_df.to_csv(perf_csv, index=False)\n",
        "print(f\"‚úì Saved: performance_comparison.csv\")\n",
        "\n",
        "# Detailed performance metrics for each variant\n",
        "detailed_metrics = []\n",
        "for v, metrics in model_performances.items():\n",
        "    variant_name = os.path.basename(v).replace('.yaml', '')\n",
        "    detailed_metrics.append({\n",
        "        'Variant': variant_name,\n",
        "        'mAP50-95': metrics['map50_95'],\n",
        "        'mAP50': metrics['map50'],\n",
        "        'mAP75': metrics['map75'],\n",
        "        'Model_Path': metrics['model_path'],\n",
        "        'YAML_Path': v\n",
        "    })\n",
        "\n",
        "detailed_df = pd.DataFrame(detailed_metrics).sort_values('mAP50-95', ascending=False)\n",
        "detailed_csv = os.path.join(metrics_dir, \"detailed_performance_metrics.csv\")\n",
        "detailed_df.to_csv(detailed_csv, index=False)\n",
        "print(f\"‚úì Saved: detailed_performance_metrics.csv\")\n",
        "\n",
        "# ============ SAVE FINAL EPOCH METRICS ============\n",
        "\n",
        "print(\"\\nüìä Extracting final epoch metrics...\")\n",
        "\n",
        "final_metrics = []\n",
        "for scale in all_losses['scale'].unique():\n",
        "    scale_data = all_losses[all_losses['scale'] == scale]\n",
        "    final_epoch = scale_data.iloc[-1]  # Last epoch\n",
        "    \n",
        "    final_metrics.append({\n",
        "        'Variant': scale,\n",
        "        'Final_Epoch': int(final_epoch['epoch']),\n",
        "        'Train_Box_Loss': final_epoch['train/box_loss'],\n",
        "        'Train_Cls_Loss': final_epoch['train/cls_loss'],\n",
        "        'Train_DFL_Loss': final_epoch['train/dfl_loss'],\n",
        "        'Val_Box_Loss': final_epoch['val/box_loss'],\n",
        "        'Val_Cls_Loss': final_epoch['val/cls_loss'],\n",
        "        'Val_DFL_Loss': final_epoch['val/dfl_loss'],\n",
        "        'Precision': final_epoch['metrics/precision(B)'],\n",
        "        'Recall': final_epoch['metrics/recall(B)'],\n",
        "        'mAP50': final_epoch['metrics/mAP50(B)'],\n",
        "        'mAP50-95': final_epoch['metrics/mAP50-95(B)'],\n",
        "        'Training_Time_Sec': final_epoch['time']\n",
        "    })\n",
        "\n",
        "final_metrics_df = pd.DataFrame(final_metrics).sort_values('mAP50-95', ascending=False)\n",
        "final_metrics_csv = os.path.join(metrics_dir, \"final_epoch_metrics.csv\")\n",
        "final_metrics_df.to_csv(final_metrics_csv, index=False)\n",
        "print(f\"‚úì Saved: final_epoch_metrics.csv\")\n",
        "\n",
        "# ============ SAVE TRAINING SUMMARY STATISTICS ============\n",
        "\n",
        "print(\"\\nüìä Calculating summary statistics...\")\n",
        "\n",
        "summary_stats = []\n",
        "for scale in all_losses['scale'].unique():\n",
        "    scale_data = all_losses[all_losses['scale'] == scale]\n",
        "    \n",
        "    summary_stats.append({\n",
        "        'Variant': scale,\n",
        "        'Epochs': len(scale_data),\n",
        "        'Total_Time_Sec': scale_data['time'].max(),\n",
        "        'Avg_Time_Per_Epoch': scale_data['time'].max() / len(scale_data),\n",
        "        'Best_mAP50': scale_data['metrics/mAP50(B)'].max(),\n",
        "        'Best_mAP50-95': scale_data['metrics/mAP50-95(B)'].max(),\n",
        "        'Best_Precision': scale_data['metrics/precision(B)'].max(),\n",
        "        'Best_Recall': scale_data['metrics/recall(B)'].max(),\n",
        "        'Final_Train_Loss': scale_data.iloc[-1]['train/box_loss'] + scale_data.iloc[-1]['train/cls_loss'] + scale_data.iloc[-1]['train/dfl_loss'],\n",
        "        'Final_Val_Loss': scale_data.iloc[-1]['val/box_loss'] + scale_data.iloc[-1]['val/cls_loss'] + scale_data.iloc[-1]['val/dfl_loss']\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_stats).sort_values('Best_mAP50-95', ascending=False)\n",
        "summary_csv = os.path.join(metrics_dir, \"training_summary_statistics.csv\")\n",
        "summary_df.to_csv(summary_csv, index=False)\n",
        "print(f\"‚úì Saved: training_summary_statistics.csv\")\n",
        "\n",
        "# ============ 1. TRAINING VS VALIDATION LOSS ============\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Training Metrics Across Model Scales', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Box Loss\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    axes[0, 0].plot(data['epoch'], data['train/box_loss'], label=f'{scale} (train)', linestyle='-')\n",
        "    axes[0, 0].plot(data['epoch'], data['val/box_loss'], label=f'{scale} (val)', linestyle='--')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Box Loss')\n",
        "axes[0, 0].set_title('Box Loss: Training vs Validation')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Class Loss\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    axes[0, 1].plot(data['epoch'], data['train/cls_loss'], label=f'{scale} (train)', linestyle='-')\n",
        "    axes[0, 1].plot(data['epoch'], data['val/cls_loss'], label=f'{scale} (val)', linestyle='--')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Classification Loss')\n",
        "axes[0, 1].set_title('Classification Loss: Training vs Validation')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# DFL Loss\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    axes[1, 0].plot(data['epoch'], data['train/dfl_loss'], label=f'{scale} (train)', linestyle='-')\n",
        "    axes[1, 0].plot(data['epoch'], data['val/dfl_loss'], label=f'{scale} (val)', linestyle='--')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('DFL Loss')\n",
        "axes[1, 0].set_title('Distribution Focal Loss: Training vs Validation')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning Rate\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    if 'lr/pg0' in data.columns:\n",
        "        axes[1, 1].plot(data['epoch'], data['lr/pg0'], label=f'{scale}')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Learning Rate')\n",
        "axes[1, 1].set_title('Learning Rate Schedule')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, '1_training_validation_losses.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"‚úì Saved: plots/1_training_validation_losses.png\")\n",
        "plt.show()\n",
        "\n",
        "# ============ 2. mAP METRICS ACROSS SCALES ============\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Mean Average Precision (mAP) Across Model Scales', fontsize=16, fontweight='bold')\n",
        "\n",
        "# mAP50\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    if 'metrics/mAP50(B)' in data.columns:\n",
        "        axes[0, 0].plot(data['epoch'], data['metrics/mAP50(B)'], label=f'{scale}', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('mAP@0.5')\n",
        "axes[0, 0].set_title('mAP@0.5 Across Epochs')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# mAP50-95\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    if 'metrics/mAP50-95(B)' in data.columns:\n",
        "        axes[0, 1].plot(data['epoch'], data['metrics/mAP50-95(B)'], label=f'{scale}', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('mAP@0.5:0.95')\n",
        "axes[0, 1].set_title('mAP@0.5:0.95 Across Epochs')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Precision\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    if 'metrics/precision(B)' in data.columns:\n",
        "        axes[1, 0].plot(data['epoch'], data['metrics/precision(B)'], label=f'{scale}', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Precision')\n",
        "axes[1, 0].set_title('Precision Across Epochs')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Recall\n",
        "for scale in all_losses['scale'].unique():\n",
        "    data = all_losses[all_losses['scale'] == scale]\n",
        "    if 'metrics/recall(B)' in data.columns:\n",
        "        axes[1, 1].plot(data['epoch'], data['metrics/recall(B)'], label=f'{scale}', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Recall')\n",
        "axes[1, 1].set_title('Recall Across Epochs')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, '2_map_precision_recall.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"‚úì Saved: plots/2_map_precision_recall.png\")\n",
        "plt.show()\n",
        "\n",
        "# ============ 3. FINAL PERFORMANCE COMPARISON ============\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart comparison\n",
        "metrics_names = ['mAP50-95', 'mAP50', 'mAP75']\n",
        "x = np.arange(len(performance_df))\n",
        "width = 0.25\n",
        "\n",
        "for i, metric in enumerate(metrics_names):\n",
        "    if metric in performance_df.columns:\n",
        "        axes[0].bar(x + i*width, performance_df[metric], width, label=metric)\n",
        "\n",
        "axes[0].set_xlabel('Model Scale')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Final Performance Comparison')\n",
        "axes[0].set_xticks(x + width)\n",
        "axes[0].set_xticklabels(performance_df['Model'])\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Heatmap of metrics\n",
        "heatmap_data = performance_df.set_index('Model')[['mAP50-95', 'mAP50', 'mAP75']].T\n",
        "sns.heatmap(heatmap_data, annot=True, fmt='.4f', cmap='YlOrRd', ax=axes[1], cbar_kws={'label': 'Score'})\n",
        "axes[1].set_title('Performance Heatmap')\n",
        "axes[1].set_xlabel('Model Scale')\n",
        "axes[1].set_ylabel('Metric')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(plots_dir, '3_final_performance_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(f\"‚úì Saved: plots/3_final_performance_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "# ============ 4. CONFUSION MATRICES COMPILATION ============\n",
        "\n",
        "print(\"\\nüìä Copying confusion matrices...\")\n",
        "for v in variants:\n",
        "    scale_name = os.path.basename(v).replace('.yaml', '')\n",
        "    cm_src = f\"runs/ablation/ablation_{scale_name}/confusion_matrix.png\"\n",
        "    \n",
        "    if os.path.exists(cm_src):\n",
        "        cm_dst = os.path.join(plots_dir, f'4_confusion_matrix_{scale_name}.png')\n",
        "        shutil.copy2(cm_src, cm_dst)\n",
        "        print(f\"‚úì Copied: plots/4_confusion_matrix_{scale_name}.png\")\n",
        "\n",
        "# ============ 5. PR CURVES & F1 CURVES ============\n",
        "\n",
        "print(\"\\nüìà Copying PR and F1 curves...\")\n",
        "for v in variants:\n",
        "    scale_name = os.path.basename(v).replace('.yaml', '')\n",
        "    \n",
        "    # PR Curve\n",
        "    pr_src = f\"runs/ablation/ablation_{scale_name}/PR_curve.png\"\n",
        "    if os.path.exists(pr_src):\n",
        "        pr_dst = os.path.join(plots_dir, f'5_PR_curve_{scale_name}.png')\n",
        "        shutil.copy2(pr_src, pr_dst)\n",
        "        print(f\"‚úì Copied: plots/5_PR_curve_{scale_name}.png\")\n",
        "    \n",
        "    # F1 Curve\n",
        "    f1_src = f\"runs/ablation/ablation_{scale_name}/F1_curve.png\"\n",
        "    if os.path.exists(f1_src):\n",
        "        f1_dst = os.path.join(plots_dir, f'6_F1_curve_{scale_name}.png')\n",
        "        shutil.copy2(f1_src, f1_dst)\n",
        "        print(f\"‚úì Copied: plots/6_F1_curve_{scale_name}.png\")\n",
        "\n",
        "# ============ 6. TRAINING CURVES FROM YOLO ============\n",
        "\n",
        "print(\"\\nüìâ Copying training result plots...\")\n",
        "for v in variants:\n",
        "    scale_name = os.path.basename(v).replace('.yaml', '')\n",
        "    results_src = f\"runs/ablation/ablation_{scale_name}/results.png\"\n",
        "    \n",
        "    if os.path.exists(results_src):\n",
        "        results_dst = os.path.join(plots_dir, f'7_training_results_{scale_name}.png')\n",
        "        shutil.copy2(results_src, results_dst)\n",
        "        print(f\"‚úì Copied: plots/7_training_results_{scale_name}.png\")\n",
        "\n",
        "# ============ COPY BEST & WORST MODELS ============\n",
        "\n",
        "print(\"\\nüíæ Copying best and worst models...\")\n",
        "\n",
        "# Copy best model\n",
        "best_src = best_model[1]['model_path']\n",
        "best_dst = os.path.join(models_dir, f\"BEST_model_{os.path.basename(best_model[0]).replace('.yaml','')}.pt\")\n",
        "shutil.copy2(best_src, best_dst)\n",
        "print(f\"‚úì Copied: BEST_model_{os.path.basename(best_model[0]).replace('.yaml','')}.pt\")\n",
        "\n",
        "# Copy worst model\n",
        "worst_src = worst_model[1]['model_path']\n",
        "worst_dst = os.path.join(models_dir, f\"WORST_model_{os.path.basename(worst_model[0]).replace('.yaml','')}.pt\")\n",
        "shutil.copy2(worst_src, worst_dst)\n",
        "print(f\"‚úì Copied: WORST_model_{os.path.basename(worst_model[0]).replace('.yaml','')}.pt\")\n",
        "\n",
        "# ============ CREATE MASTER SUMMARY FILE ============\n",
        "\n",
        "print(\"\\nüìÑ Creating master summary report...\")\n",
        "\n",
        "master_summary = {\n",
        "    'Study_Info': {\n",
        "        'Total_Variants_Trained': len(variants),\n",
        "        'Variants': list(performance_df['Model']),\n",
        "        'Data_YAML': DATA_YAML_PATH,\n",
        "        'Results_Directory': results_dir\n",
        "    },\n",
        "    'Best_Model': {\n",
        "        'Variant': os.path.basename(best_model[0]).replace('.yaml',''),\n",
        "        'mAP50-95': best_model[1]['map50_95'],\n",
        "        'mAP50': best_model[1]['map50'],\n",
        "        'mAP75': best_model[1]['map75'],\n",
        "        'Model_Path': best_dst\n",
        "    },\n",
        "    'Worst_Model': {\n",
        "        'Variant': os.path.basename(worst_model[0]).replace('.yaml',''),\n",
        "        'mAP50-95': worst_model[1]['map50_95'],\n",
        "        'mAP50': worst_model[1]['map50'],\n",
        "        'mAP75': worst_model[1]['map75'],\n",
        "        'Model_Path': worst_dst\n",
        "    },\n",
        "    'Files_Generated': {\n",
        "        'CSV_Files': [\n",
        "            'all_variants_training_metrics.csv',\n",
        "            'performance_comparison.csv',\n",
        "            'detailed_performance_metrics.csv',\n",
        "            'final_epoch_metrics.csv',\n",
        "            'training_summary_statistics.csv'\n",
        "        ] + [f'training_metrics_{os.path.basename(v).replace(\".yaml\",\"\")}.csv' for v in variants],\n",
        "        'Plot_Files': len([f for f in os.listdir(plots_dir) if f.endswith('.png')]),\n",
        "        'Model_Files': 2\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary as text file\n",
        "summary_file = os.path.join(results_dir, \"MASTER_SUMMARY.txt\")\n",
        "with open(summary_file, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"YOLO ABLATION STUDY - MASTER SUMMARY\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    \n",
        "    f.write(\"STUDY INFORMATION\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Total Variants Trained: {master_summary['Study_Info']['Total_Variants_Trained']}\\n\")\n",
        "    f.write(f\"Variants: {', '.join(master_summary['Study_Info']['Variants'])}\\n\")\n",
        "    f.write(f\"Results Directory: {results_dir}\\n\\n\")\n",
        "    \n",
        "    f.write(\"BEST PERFORMING MODEL\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Variant: {master_summary['Best_Model']['Variant']}\\n\")\n",
        "    f.write(f\"mAP50-95: {master_summary['Best_Model']['mAP50-95']:.4f}\\n\")\n",
        "    f.write(f\"mAP50: {master_summary['Best_Model']['mAP50']:.4f}\\n\")\n",
        "    f.write(f\"mAP75: {master_summary['Best_Model']['mAP75']:.4f}\\n\")\n",
        "    f.write(f\"Model Path: {master_summary['Best_Model']['Model_Path']}\\n\\n\")\n",
        "    \n",
        "    f.write(\"WORST PERFORMING MODEL\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Variant: {master_summary['Worst_Model']['Variant']}\\n\")\n",
        "    f.write(f\"mAP50-95: {master_summary['Worst_Model']['mAP50-95']:.4f}\\n\")\n",
        "    f.write(f\"mAP50: {master_summary['Worst_Model']['mAP50']:.4f}\\n\")\n",
        "    f.write(f\"mAP75: {master_summary['Worst_Model']['mAP75']:.4f}\\n\")\n",
        "    f.write(f\"Model Path: {master_summary['Worst_Model']['Model_Path']}\\n\\n\")\n",
        "    \n",
        "    f.write(\"FILES GENERATED\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"CSV Metric Files: {len(master_summary['Files_Generated']['CSV_Files'])}\\n\")\n",
        "    f.write(f\"Plot/Visualization Files: {master_summary['Files_Generated']['Plot_Files']}\\n\")\n",
        "    f.write(f\"Model Files: {master_summary['Files_Generated']['Model_Files']}\\n\\n\")\n",
        "    \n",
        "    f.write(\"DETAILED PERFORMANCE RANKING\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    for i, row in performance_df.iterrows():\n",
        "        f.write(f\"{i+1}. {row['Model']:10s} | mAP50-95: {row['mAP50-95']:.4f} | mAP50: {row['mAP50']:.4f} | mAP75: {row['mAP75']:.4f}\\n\")\n",
        "\n",
        "print(f\"‚úì Saved: MASTER_SUMMARY.txt\")\n",
        "\n",
        "# ============ FINAL SUMMARY ============\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ COMPREHENSIVE EVALUATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìÅ ALL RESULTS SAVED TO: {results_dir}\")\n",
        "print(f\"\\nüìä CSV METRICS ({len(os.listdir(metrics_dir))} files):\")\n",
        "print(f\"   ‚Ä¢ all_variants_training_metrics.csv\")\n",
        "print(f\"   ‚Ä¢ performance_comparison.csv\")\n",
        "print(f\"   ‚Ä¢ detailed_performance_metrics.csv\")\n",
        "print(f\"   ‚Ä¢ final_epoch_metrics.csv\")\n",
        "print(f\"   ‚Ä¢ training_summary_statistics.csv\")\n",
        "print(f\"   ‚Ä¢ Individual variant CSVs for each model\")\n",
        "print(f\"\\nüìà VISUALIZATIONS ({len([f for f in os.listdir(plots_dir) if f.endswith('.png')])} plots):\")\n",
        "print(f\"   ‚Ä¢ Training vs Validation Losses\")\n",
        "print(f\"   ‚Ä¢ mAP Metrics (mAP50, mAP50-95, Precision, Recall)\")\n",
        "print(f\"   ‚Ä¢ Performance Comparison Charts\")\n",
        "print(f\"   ‚Ä¢ Confusion Matrices\")\n",
        "print(f\"   ‚Ä¢ Precision-Recall Curves\")\n",
        "print(f\"   ‚Ä¢ F1 Score Curves\")\n",
        "print(f\"   ‚Ä¢ Training Results Plots\")\n",
        "print(f\"\\nüíæ MODELS:\")\n",
        "print(f\"   ‚Ä¢ Best: {best_dst}\")\n",
        "print(f\"   ‚Ä¢ Worst: {worst_dst}\")\n",
        "print(f\"\\nüìÑ MASTER SUMMARY: {summary_file}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6ca463",
      "metadata": {},
      "source": [
        "### Model Format Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xg1v4-8cyJDo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "xg1v4-8cyJDo",
        "outputId": "16990b6e-ebcc-418f-9287-5f8eac6d27b2"
      },
      "outputs": [],
      "source": [
        "############### Interactive Trained Model Conversion #############################\n",
        "\n",
        "import os\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog, simpledialog, messagebox\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ============ STEP 1: SELECT MODEL FILE ============\n",
        "\n",
        "root = tk.Tk()\n",
        "root.withdraw()\n",
        "root.attributes('-topmost', True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"YOLO MODEL EXPORT TOOL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nStep 1: Select the YOLO model file to convert...\")\n",
        "model_path = filedialog.askopenfilename(\n",
        "    title=\"Select YOLO Model File (.pt)\",\n",
        "    filetypes=[(\"PyTorch Model\", \"*.pt\"), (\"All files\", \"*.*\")]\n",
        ")\n",
        "\n",
        "if not model_path:\n",
        "    print(\" No model file selected!\")\n",
        "    root.destroy()\n",
        "    raise ValueError(\"No model file selected!\")\n",
        "\n",
        "print(f\"‚úì Selected model: {model_path}\")\n",
        "\n",
        "# ============ STEP 2: SELECT EXPORT FORMAT ============\n",
        "\n",
        "print(\"\\nStep 2: Select export format...\")\n",
        "\n",
        "# Create format selection window\n",
        "format_window = tk.Toplevel()\n",
        "format_window.title(\"Select Export Format\")\n",
        "format_window.geometry(\"400x500\")\n",
        "format_window.attributes('-topmost', True)\n",
        "\n",
        "tk.Label(\n",
        "    format_window, \n",
        "    text=\"Select Export Format:\", \n",
        "    font=(\"Arial\", 12, \"bold\")\n",
        ").pack(pady=10)\n",
        "\n",
        "# Available formats\n",
        "formats = {\n",
        "    \"TorchScript\": \"torchscript\",\n",
        "    \"ONNX\": \"onnx\",\n",
        "    \"OpenVINO\": \"openvino\",\n",
        "    \"TensorRT\": \"engine\",\n",
        "    \"CoreML\": \"coreml\",\n",
        "    \"TensorFlow SavedModel\": \"saved_model\",\n",
        "    \"TensorFlow GraphDef\": \"pb\",\n",
        "    \"TensorFlow Lite\": \"tflite\",\n",
        "    \"TensorFlow Edge TPU\": \"edgetpu\",\n",
        "    \"TensorFlow.js\": \"tfjs\",\n",
        "    \"PaddlePaddle\": \"paddle\",\n",
        "    \"NCNN\": \"ncnn\"\n",
        "}\n",
        "\n",
        "selected_format = tk.StringVar(value=\"torchscript\")\n",
        "\n",
        "# Create radio buttons for each format\n",
        "for display_name, format_code in formats.items():\n",
        "    tk.Radiobutton(\n",
        "        format_window,\n",
        "        text=f\"{display_name} (.{format_code})\",\n",
        "        variable=selected_format,\n",
        "        value=format_code,\n",
        "        font=(\"Arial\", 10)\n",
        "    ).pack(anchor='w', padx=30, pady=3)\n",
        "\n",
        "format_chosen = [None]\n",
        "\n",
        "def on_format_submit():\n",
        "    format_chosen[0] = selected_format.get()\n",
        "    format_window.destroy()\n",
        "\n",
        "tk.Button(\n",
        "    format_window,\n",
        "    text=\"Continue\",\n",
        "    command=on_format_submit,\n",
        "    bg=\"green\",\n",
        "    fg=\"white\",\n",
        "    font=(\"Arial\", 10, \"bold\"),\n",
        "    padx=20,\n",
        "    pady=5\n",
        ").pack(pady=15)\n",
        "\n",
        "format_window.wait_window()\n",
        "\n",
        "if not format_chosen[0]:\n",
        "    print(\"‚ùå No format selected!\")\n",
        "    root.destroy()\n",
        "    raise ValueError(\"No format selected!\")\n",
        "\n",
        "export_format = format_chosen[0]\n",
        "print(f\"‚úì Selected format: {export_format}\")\n",
        "\n",
        "# ============ STEP 3: SELECT OUTPUT DIRECTORY ============\n",
        "\n",
        "print(\"\\nStep 3: Select where to save the converted model...\")\n",
        "\n",
        "output_dir = filedialog.askdirectory(\n",
        "    title=\"Select Output Directory\"\n",
        ")\n",
        "\n",
        "if not output_dir:\n",
        "    print(\"‚ö†Ô∏è  No output directory selected - using model's directory\")\n",
        "    output_dir = os.path.dirname(model_path)\n",
        "\n",
        "print(f\"‚úì Output directory: {output_dir}\")\n",
        "\n",
        "root.destroy()\n",
        "\n",
        "# ============ STEP 4: EXPORT MODEL ============\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPORTING MODEL\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model: {os.path.basename(model_path)}\")\n",
        "print(f\"Format: {export_format}\")\n",
        "print(f\"Output: {output_dir}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    # Load model\n",
        "    model = YOLO(model_path)\n",
        "    \n",
        "    # Export model\n",
        "    print(\"üîÑ Exporting... (this may take a few minutes)\")\n",
        "    exported_path = model.export(format=export_format)\n",
        "    \n",
        "    # Move exported file to selected directory if different\n",
        "    if exported_path and os.path.dirname(exported_path) != output_dir:\n",
        "        import shutil\n",
        "        new_path = os.path.join(output_dir, os.path.basename(exported_path))\n",
        "        shutil.move(exported_path, new_path)\n",
        "        exported_path = new_path\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\" EXPORT SUCCESSFUL!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Converted file saved to:\")\n",
        "    print(f\"  {exported_path}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Show success dialog\n",
        "    messagebox.showinfo(\n",
        "        \"Export Complete\",\n",
        "        f\"Model successfully exported!\\n\\nSaved to:\\n{exported_path}\"\n",
        "    )\n",
        "    \n",
        "except Exception as e:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚ùå EXPORT FAILED\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    messagebox.showerror(\n",
        "        \"Export Failed\",\n",
        "        f\"Failed to export model:\\n\\n{str(e)}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6d8d23",
      "metadata": {},
      "source": [
        "### Simulate Model for Detection Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8550bc8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO (r'C:\\Users\\Cloud Playground\\OneDrive - Sam Houston State University\\Documents\\SHSU\\Fall 2025\\Semina\\Configuration Experiment\\datasets\\best_worst_models\\BEST_model_yolo11s.pt')\n",
        "results = model(source = \"https://www.youtube.com/watch?v=TwLXjahWBvo\" , show = True, conf = 0.4, save = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
